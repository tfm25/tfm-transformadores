{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c470fe71-d608-41bd-ae23-a5335426d5be",
   "metadata": {},
   "source": [
    "# **Leer data transformadores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c12978-8472-4e5c-84c7-230e2483a972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lee el archivo CSV\n",
    "df_transformadores = pd.read_csv('df_rellenado_con_nans.csv')\n",
    "\n",
    "# Muestra las primeras filas del DataFrame\n",
    "df_transformadores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a680f4b-4db0-448d-ab8b-776545dff7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformadores['estacion_2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1d38b1-4fec-4afa-aaff-04a0a90af4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = [\n",
    "    'Fecha y hora',\n",
    "    \"SE_San_Rafael.Trf_San_Rafael_T1 Potencia activa media (kW)\",\n",
    "    \"SE_San_Rafael.Trf_San_Rafael_T1 Potencia reactiva media (kVAr)\",\n",
    "    \"SE_San_Rafael.Trf_San_Rafael_T3 Potencia activa media (kW)\",\n",
    "    \"SE_San_Rafael.Trf_San_Rafael_T3 Potencia reactiva media (kVAr)\",\n",
    "    \"SE_San_Felipe.Trf_San_Felipe_T1 Potencia activa media (kW)\",\n",
    "    \"SE_San_Felipe.Trf_San_Felipe_T1 Potencia reactiva media (kVAr)\",\n",
    "    \"SE_San_Felipe.Trf_San_Felipe_T2 Potencia activa media (kW)\",\n",
    "    \"SE_San_Felipe.Trf_San_Felipe_T2 Potencia reactiva media (kVAr)\",\n",
    "    \"SE_Concon.Trf_Concon_T2_2 Potencia activa media (kW)\",\n",
    "    \"SE_Concon.Trf_Concon_T2_2 Potencia reactiva media (kVAr)\",\n",
    "    'estacion',\n",
    "    'estacion_2'\n",
    "]\n",
    "\n",
    "df_transformadores = df_transformadores[columnas]\n",
    "\n",
    "df_transformadores['Fecha y hora'] = pd.to_datetime(df_transformadores['Fecha y hora'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a324baea-0740-4e4a-bd69-9f3aa6ee1f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "transformador_columnas_p = [\n",
    " \"SE_San_Rafael.Trf_San_Rafael_T1 Potencia activa media (kW)\",\n",
    " \"SE_San_Rafael.Trf_San_Rafael_T3 Potencia activa media (kW)\",\n",
    " \"SE_San_Felipe.Trf_San_Felipe_T1 Potencia activa media (kW)\",\n",
    " \"SE_San_Felipe.Trf_San_Felipe_T2 Potencia activa media (kW)\", \n",
    " \"SE_Concon.Trf_Concon_T2_2 Potencia activa media (kW)\"\n",
    "]\n",
    "    \n",
    "\n",
    "transformador_columnas_q = [\n",
    " \"SE_San_Rafael.Trf_San_Rafael_T1 Potencia reactiva media (kVAr)\", \n",
    " \"SE_San_Rafael.Trf_San_Rafael_T3 Potencia reactiva media (kVAr)\", \n",
    " \"SE_San_Felipe.Trf_San_Felipe_T1 Potencia reactiva media (kVAr)\",\n",
    " \"SE_San_Felipe.Trf_San_Felipe_T2 Potencia reactiva media (kVAr)\",\n",
    "\"SE_Concon.Trf_Concon_T2_2 Potencia reactiva media (kVAr)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03667da6-c4a3-4bba-88bd-3d92daf451df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir ambas listas de columnas\n",
    "columnas_a_convertir = transformador_columnas_p + transformador_columnas_q\n",
    "\n",
    "# Aplicar la conversión: dividir por 1000\n",
    "df_transformadores[columnas_a_convertir] = df_transformadores[columnas_a_convertir] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3080edc-94e6-4d93-a818-a6ccef53ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformadores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5c3ffc-4b0c-4e0a-b9e6-dc0b0619c848",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformadores['Fecha y hora'] = pd.to_datetime(df_transformadores['Fecha y hora'])\n",
    "\n",
    "# Mostrar la fecha mínima y máxima\n",
    "fecha_min = df_transformadores['Fecha y hora'].min()\n",
    "fecha_max = df_transformadores['Fecha y hora'].max()\n",
    "\n",
    "print(\"Fecha mínima:\", fecha_min)\n",
    "print(\"Fecha máxima:\", fecha_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756c7fde-2374-47af-9ed8-c7138c3581ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las fechas de inicio y fin\n",
    "fecha_inicio = pd.to_datetime('2022-09-01 00:00:00')\n",
    "fecha_fin = pd.to_datetime('2025-04-08 00:00:00')\n",
    "\n",
    "# Filtrar el DataFrame para que solo contenga registros entre fecha_inicio y fecha_fin\n",
    "df_transformadores = df_transformadores[(df_transformadores['Fecha y hora'] >= fecha_inicio) & (df_transformadores['Fecha y hora'] <= fecha_fin)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed6512-d2f4-4d63-87ee-d18fffecefa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformadores.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cee4ed-6546-4b1a-bf91-c22f0258524c",
   "metadata": {},
   "source": [
    "# **Instalación de librerias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803a797f-bb24-4055-bd30-ec15fbccad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f207fb-81a9-4439-b5b4-b0f901fb2120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "import numpy as np\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d352aed6-089f-47d1-a5f3-69342cd75381",
   "metadata": {},
   "source": [
    "# **Modelos Invierten Q**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3103e010-4358-4129-9c8f-5e3f97b17d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_mape(y_true, y_pred, min_denominador=1.0):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true >= min_denominador\n",
    "    if np.any(mask):\n",
    "        return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a51681-6fc1-4b02-bbac-88bbb7944568",
   "metadata": {},
   "source": [
    "## pruebas feriados (GAP 3 weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca47724e-5716-440f-be66-d67ec5bfb2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejecutar_modelo_prophet_parametros_estacion_manual(df, columna, fecha_inicio_test, mostrar_grafico=False, ruta_guardado=None):\n",
    "    # Preparar datos\n",
    "    df_prophet = df[['Fecha y hora', columna, 'estacion']].dropna().rename(columns={\n",
    "        'Fecha y hora': 'ds', columna: 'y'\n",
    "    })\n",
    "    df_prophet['ds'] = pd.to_datetime(df_prophet['ds'])\n",
    "\n",
    "    # Convertir 'estacion' en dummies\n",
    "    df_prophet = pd.get_dummies(df_prophet, columns=['estacion'], prefix='est')\n",
    "    columnas_estacion = [col for col in df_prophet.columns if col.startswith('est_')]\n",
    "\n",
    "    # Fechas clave\n",
    "    fecha_inicio_test = pd.to_datetime(fecha_inicio_test)\n",
    "    fecha_fin_test = fecha_inicio_test + pd.Timedelta(days=1)\n",
    "    \n",
    "    fecha_fin_train_eval = fecha_inicio_test - pd.Timedelta(weeks=3)\n",
    "    fecha_inicio_train = fecha_fin_train_eval - pd.Timedelta(weeks=52)\n",
    "    fecha_inicio_train_eval = fecha_fin_train_eval - pd.Timedelta(days=1)\n",
    "    \n",
    "    # Filtrar conjuntos\n",
    "    df_test = df_prophet[(df_prophet['ds'] >= fecha_inicio_test) & (df_prophet['ds'] < fecha_fin_test)].copy()\n",
    "    df_train_eval = df_prophet[(df_prophet['ds'] >= fecha_inicio_train_eval) & (df_prophet['ds'] < fecha_fin_train_eval)].copy()\n",
    "    df_train = df_prophet[df_prophet['ds'] <= fecha_fin_train_eval].copy()\n",
    "\n",
    "    # Crear y configurar el modelo\n",
    "    m = Prophet(\n",
    "        daily_seasonality=False,\n",
    "        weekly_seasonality=False,\n",
    "        yearly_seasonality=False,\n",
    "        n_changepoints=50\n",
    "    )\n",
    "    m.add_seasonality(name='daily_hour', period=1, fourier_order=20)\n",
    "    m.add_seasonality(name='weekly_custom', period=7, fourier_order=30)\n",
    "    m.add_seasonality(name='yearly_custom', period=365.25, fourier_order=10)\n",
    "\n",
    "    for col in columnas_estacion:\n",
    "        m.add_regressor(col)\n",
    "\n",
    "    # Entrenamiento\n",
    "    m.fit(df_train)\n",
    "\n",
    "    # Preparar fechas futuras\n",
    "    future = pd.concat([df_train_eval[['ds']], df_test[['ds']]]).drop_duplicates().sort_values('ds')\n",
    "    future = future.merge(df_prophet[['ds'] + columnas_estacion], on='ds', how='left')\n",
    "\n",
    "    # Predicción\n",
    "    forecast = m.predict(future)\n",
    "    forecast_train_eval = forecast[forecast['ds'].isin(df_train_eval['ds'])]\n",
    "    forecast_test = forecast[forecast['ds'].isin(df_test['ds'])]\n",
    "\n",
    "    df_train_eval = df_train_eval.set_index('ds').join(forecast_train_eval.set_index('ds')[['yhat']], how='inner')\n",
    "    df_test_eval = df_test.set_index('ds').join(forecast_test.set_index('ds')[['yhat']], how='inner')\n",
    "\n",
    "    # Métricas\n",
    "    mae_train = mean_absolute_error(df_train_eval['y'], df_train_eval['yhat'])\n",
    "    rmse_train = np.sqrt(mean_squared_error(df_train_eval['y'], df_train_eval['yhat']))\n",
    "    mape_train = calcular_mape(df_train_eval['y'], df_train_eval['yhat'])\n",
    "\n",
    "    mae_test = mean_absolute_error(df_test_eval['y'], df_test_eval['yhat'])\n",
    "    rmse_test = np.sqrt(mean_squared_error(df_test_eval['y'], df_test_eval['yhat']))\n",
    "    mape_test = calcular_mape(df_test_eval['y'], df_test_eval['yhat'])\n",
    "\n",
    "    # Gráfico opcional\n",
    "    if mostrar_grafico or ruta_guardado:\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(df_test_eval.index, df_test_eval['y'], label='Real')\n",
    "        plt.plot(df_test_eval.index, df_test_eval['yhat'], label='Predicción')\n",
    "        plt.title(f'{columna} [{fecha_inicio_test.date()}]')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if ruta_guardado:\n",
    "            plt.savefig(ruta_guardado)\n",
    "        if mostrar_grafico:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "\n",
    "    # Armar resultados de métricas\n",
    "    resultados_metricas = {\n",
    "        'transformador': columna,\n",
    "        'fecha_inicio_test': fecha_inicio_test.date(),\n",
    "        'MAE_train': mae_train, 'RMSE_train': rmse_train, 'MAPE_train': mape_train,\n",
    "        'MAE_test': mae_test, 'RMSE_test': rmse_test, 'MAPE_test': mape_test\n",
    "    }\n",
    "\n",
    "    # Preparar df_test_eval para exportar\n",
    "    df_test_eval = df_test_eval.reset_index()\n",
    "    df_test_eval['transformador'] = columna\n",
    "    df_test_eval = df_test_eval.rename(columns={'y': 'real', 'yhat': 'predicho'})\n",
    "\n",
    "    return resultados_metricas, df_test_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "551c471a-5abf-487e-b9b0-e5eb362481a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Años considerados para feriados: [2024, 2025]\n",
      "Rango de fechas: 2024-04-01 hasta 2025-03-30\n",
      "Feriados en rango filtrados:\n",
      "2024-05-01 00:00:00\n",
      "2024-05-21 00:00:00\n",
      "2024-06-20 00:00:00\n",
      "2024-06-29 00:00:00\n",
      "2024-07-16 00:00:00\n",
      "2024-08-15 00:00:00\n",
      "2024-09-18 00:00:00\n",
      "2024-09-19 00:00:00\n",
      "2024-09-20 00:00:00\n",
      "2024-10-12 00:00:00\n",
      "2024-10-31 00:00:00\n",
      "2024-11-01 00:00:00\n",
      "2024-12-08 00:00:00\n",
      "2024-12-25 00:00:00\n",
      "2025-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:39:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:40:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      "14:40:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:41:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      "14:41:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:42:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "14:42:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:45:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "14:45:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:46:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "14:47:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:49:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "14:49:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:52:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      "14:52:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:56:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "14:56:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:58:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      "14:58:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:01:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:01:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:03:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:03:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:07:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:07:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:11:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:11:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:15:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:15:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:18:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:18:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:19:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:19:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:19:37 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:19:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:20:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:20:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:20:38 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:20:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:21:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:21:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:21:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:21:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:22:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:22:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:22:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:22:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:23:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:23:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:24:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:25:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:25:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:27:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:27:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:28:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:28:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:29:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:29:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:30:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:30:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:31:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:31:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:32:26 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:32:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:33:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:33:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:34:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:34:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:35:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:35:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:36:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:36:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:38:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:38:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:39:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:39:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:40:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:40:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:41:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:41:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:42:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:42:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:44:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:44:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:45:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:45:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:47:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:47:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:48:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:48:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:49:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:49:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:50:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:50:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:51:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:51:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:52:33 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:52:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:53:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:54:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:55:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:55:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:57:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:57:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:59:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:59:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:00:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:00:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:02:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:02:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:03:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:03:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:05:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:05:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:07:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:07:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:10:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:10:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:12:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:12:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:16:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:16:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:18:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:18:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:21:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:21:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:24:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:26:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:26:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:30:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:30:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:33:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:33:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:36:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:36:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:40:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:40:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:43:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:43:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:47:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:47:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:51:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:51:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:53:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:53:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:57:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       transformador fecha_inicio_test  \\\n",
      "0  SE_San_Rafael.Trf_San_Rafael_T1 Potencia react...        2024-05-01   \n",
      "1  SE_San_Rafael.Trf_San_Rafael_T1 Potencia react...        2024-05-21   \n",
      "2  SE_San_Rafael.Trf_San_Rafael_T1 Potencia react...        2024-06-20   \n",
      "3  SE_San_Rafael.Trf_San_Rafael_T1 Potencia react...        2024-06-29   \n",
      "4  SE_San_Rafael.Trf_San_Rafael_T1 Potencia react...        2024-07-16   \n",
      "\n",
      "   MAE_train  RMSE_train  MAPE_train  MAE_test  RMSE_test   MAPE_test  \\\n",
      "0   0.806526    0.915320   27.504228  0.948224   1.073254   49.888879   \n",
      "1   0.505912    0.675702   26.352083  2.633050   2.873819  239.670442   \n",
      "2   0.685615    0.758064   14.734994  3.399753   3.624362  193.286541   \n",
      "3   1.748671    1.933062   93.070653  3.095984   3.261473  193.751296   \n",
      "4   0.900856    1.001684   48.467979  0.606459   0.698293   37.370444   \n",
      "\n",
      "  fecha_test                                festivo  anio  \n",
      "0 2024-05-01               Día Nacional del Trabajo  2024  \n",
      "1 2024-05-21             Día de las Glorias Navales  2024  \n",
      "2 2024-06-20  Día Nacional de los Pueblos Indígenas  2024  \n",
      "3 2024-06-29                  San Pedro y San Pablo  2024  \n",
      "4 2024-07-16                      Virgen del Carmen  2024  \n",
      "                   ds      real  est_invierno  est_otoño  est_primavera  \\\n",
      "0 2024-05-01 00:00:00  0.852461         False       True          False   \n",
      "1 2024-05-01 00:15:00  0.784596         False       True          False   \n",
      "2 2024-05-01 00:30:00  0.724972         False       True          False   \n",
      "3 2024-05-01 00:45:00  0.791041         False       True          False   \n",
      "4 2024-05-01 01:00:00  0.869930         False       True          False   \n",
      "\n",
      "   est_verano  predicho                                      transformador  \\\n",
      "0       False -0.243525  SE_San_Rafael.Trf_San_Rafael_T1 Potencia react...   \n",
      "1       False -0.275533  SE_San_Rafael.Trf_San_Rafael_T1 Potencia react...   \n",
      "2       False -0.297810  SE_San_Rafael.Trf_San_Rafael_T1 Potencia react...   \n",
      "3       False -0.329195  SE_San_Rafael.Trf_San_Rafael_T1 Potencia react...   \n",
      "4       False -0.370767  SE_San_Rafael.Trf_San_Rafael_T1 Potencia react...   \n",
      "\n",
      "  fecha_test                   festivo  anio  \n",
      "0 2024-05-01  Día Nacional del Trabajo  2024  \n",
      "1 2024-05-01  Día Nacional del Trabajo  2024  \n",
      "2 2024-05-01  Día Nacional del Trabajo  2024  \n",
      "3 2024-05-01  Día Nacional del Trabajo  2024  \n",
      "4 2024-05-01  Día Nacional del Trabajo  2024  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import holidays\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1)  Carpeta donde guardar los PNG\n",
    "# -------------------------------------------------------------------\n",
    "carpeta_graficos = Path(\"graficos_resultados_festivos_CL\")\n",
    "carpeta_graficos.mkdir(exist_ok=True)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2) solo 2024\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "fecha_inicio = pd.Timestamp(\"2024-04-01\")\n",
    "fecha_fin    = pd.Timestamp(\"2025-03-30\")\n",
    "\n",
    "years = list(range(fecha_inicio.year, fecha_fin.year + 1))\n",
    "\n",
    "print(f\"Años considerados para feriados: {years}\")\n",
    "print(f\"Rango de fechas: {fecha_inicio.date()} hasta {fecha_fin.date()}\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3)  Construir feriados solo para esos años  ←  (igual que antes)\n",
    "# -------------------------------------------------------------------\n",
    "feriados_cl = holidays.CountryHoliday(\"CL\", years=years)\n",
    "\n",
    "fechas_en_rango = [\n",
    "    pd.Timestamp(d)\n",
    "    for d in feriados_cl\n",
    "    if fecha_inicio <= pd.Timestamp(d) <= fecha_fin\n",
    "]\n",
    "\n",
    "print(\"Feriados en rango filtrados:\")\n",
    "for f in fechas_en_rango:\n",
    "    print(f)\n",
    "\n",
    "fechas_test_por_festivo = {}\n",
    "for fecha in fechas_en_rango:\n",
    "    anio = fecha.year\n",
    "    fechas_test_por_festivo.setdefault(anio, []).append(fecha)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4)  Bucle principal – sin cambios …\n",
    "# -------------------------------------------------------------------\n",
    "resultados = []\n",
    "predicciones_todas = []\n",
    "\n",
    "for transformador in transformador_columnas_q:\n",
    "    for anio, fechas in fechas_test_por_festivo.items():\n",
    "        for fecha in fechas:\n",
    "            # --- verificación rápida de datos válidos (opcional) ---\n",
    "            sub_df = df_transformadores[df_transformadores['Fecha y hora'].dt.date == fecha.date()]\n",
    "            if sub_df[transformador].dropna().shape[0] < 2:\n",
    "                print(f\"Saltando {transformador}, festivo {fecha.date()}: <2 datos válidos\")\n",
    "                continue\n",
    "            # --------------------------------------------------------\n",
    "\n",
    "            try:\n",
    "                fecha_str = fecha.strftime(\"%Y-%m-%d\")\n",
    "                nombre_archivo = (\n",
    "                    transformador.replace(\" \", \"_\")\n",
    "                                 .replace(\".\", \"_\")\n",
    "                                 .replace(\"(\", \"\")\n",
    "                                 .replace(\")\", \"\")\n",
    "                                 .replace(\"/\", \"_\")\n",
    "                )\n",
    "                ruta_grafico = carpeta_graficos / f\"{nombre_archivo}_{fecha_str}.png\"\n",
    "\n",
    "                resultado, predicciones_test = ejecutar_modelo_prophet_parametros_estacion_manual(\n",
    "                    df_transformadores,\n",
    "                    columna=transformador,\n",
    "                    fecha_inicio_test=fecha,\n",
    "                    mostrar_grafico=False,\n",
    "                    ruta_guardado=ruta_grafico\n",
    "                )\n",
    "\n",
    "                resultado.update({\n",
    "                    \"transformador\": transformador,\n",
    "                    \"fecha_test\":    fecha,\n",
    "                    \"festivo\":       feriados_cl.get(fecha),\n",
    "                    \"anio\":          anio\n",
    "                })\n",
    "                resultados.append(resultado)\n",
    "\n",
    "                predicciones_test[\"fecha_test\"] = fecha\n",
    "                predicciones_test[\"festivo\"]    = feriados_cl.get(fecha)\n",
    "                predicciones_test[\"anio\"]       = anio\n",
    "                predicciones_todas.append(predicciones_test)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error en {transformador}, festivo {fecha}: {e}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 5)  Consolidar resultados\n",
    "# -------------------------------------------------------------------\n",
    "df_resultados   = pd.DataFrame(resultados)\n",
    "df_predicciones = pd.concat(predicciones_todas, ignore_index=True)\n",
    "\n",
    "print(df_resultados.head())\n",
    "print(df_predicciones.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75be3cb2-0ae3-4327-99da-a69e8099809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(\"resultados_prophet_Q_no_invierte_festivos.xlsx\", engine=\"openpyxl\") as writer:\n",
    "    df_resultados.to_excel(writer, sheet_name=\"Metricas\", index=False)\n",
    "    df_predicciones.to_excel(writer, sheet_name=\"Predicciones\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed5b3ed-5ec5-4d31-838e-9d90c07761a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
